# WARP.md

This file provides guidance to WARP (warp.dev) when working with code in this repository.

## Project Overview

StratumAI is a production-ready Python module that provides a unified, abstracted interface for accessing multiple frontier LLM providers (OpenAI, Anthropic, Google, DeepSeek, Groq, Grok, OpenRouter, Ollama) through a consistent API. The project demonstrates advanced API abstraction, design patterns (strategy, factory), multi-provider integration, production engineering (error handling, retry logic, cost tracking), and Python best practices (type hints, abstract base classes, decorators).

## Development Environment Setup

### Initial Setup
```bash
# Create virtual environment
python3 -m venv .venv

# Activate virtual environment
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### Using uv (Alternative)
```bash
# Create virtual environment with uv
uv venv

# Activate virtual environment
source .venv/bin/activate

# Install dependencies with uv
uv pip install -r requirements.txt
```

## Project Structure

```txt
stratumai/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ WARP.md                # This file (development guidance)
‚îú‚îÄ‚îÄ requirements.txt       # Python dependencies
‚îú‚îÄ‚îÄ .venv/                 # Virtual environment
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ project-status.md              # 5-week timeline with detailed phases
‚îÇ   ‚îî‚îÄ‚îÄ stratumai-technical-approach.md # Comprehensive technical design (1,232 lines)
‚îî‚îÄ‚îÄ llm_abstraction/                    # Main package (to be implemented)
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ client.py                       # Unified LLMClient
    ‚îú‚îÄ‚îÄ models.py                       # Data models (Message, ChatRequest, ChatResponse)
    ‚îú‚îÄ‚îÄ config.py                       # Model catalogs and cost tables
    ‚îú‚îÄ‚îÄ exceptions.py                   # Custom exceptions
    ‚îú‚îÄ‚îÄ utils.py                        # Helper functions
    ‚îú‚îÄ‚îÄ router.py                       # Intelligent routing
    ‚îî‚îÄ‚îÄ providers/
        ‚îú‚îÄ‚îÄ base.py                     # BaseProvider abstract class
        ‚îú‚îÄ‚îÄ openai.py                   # OpenAI implementation
        ‚îú‚îÄ‚îÄ anthropic.py                # Anthropic implementation
        ‚îú‚îÄ‚îÄ google.py                   # Google Gemini implementation
        ‚îú‚îÄ‚îÄ deepseek.py                 # DeepSeek implementation
        ‚îú‚îÄ‚îÄ groq.py                     # Groq implementation
        ‚îú‚îÄ‚îÄ grok.py                     # Grok (X.AI) implementation
        ‚îú‚îÄ‚îÄ openrouter.py               # OpenRouter implementation
        ‚îî‚îÄ‚îÄ ollama.py                   # Ollama local models
```

## Testing

### Running Tests
```bash
# Run all tests
pytest

# Run with verbose output
pytest -v

# Run specific test file
pytest tests/test_example.py

# Run specific test
pytest tests/test_example.py::test_function_name
```

## Common Workflows

### Starting Development
```bash
# Activate virtual environment
source .venv/bin/activate

# Install/update dependencies
pip install -r requirements.txt

# [Additional setup steps]
```

### Adding Dependencies
```bash
# Install new package
pip install package-name

# Update requirements.txt
pip freeze > requirements.txt
```

## Architecture Principles

**Design Principles:**
- **Abstraction First**: Hide provider-specific differences behind unified interface
- **Strategy Pattern**: Each provider implements common BaseProvider interface
- **Configuration-Driven**: Model catalogs, cost tables, capability matrices externalized
- **Fail-Safe**: Automatic retry with exponential backoff and fallback models
- **Cost-Aware**: Track every token and enforce budget limits

### Key Design Decisions
1. **Provider Strategy Pattern**: All providers inherit from BaseProvider abstract class, ensuring consistent interface
2. **OpenAI-Compatible Pattern**: Providers with OpenAI-compatible APIs (Gemini, DeepSeek, Groq, Grok, Ollama) share common base class
3. **Unified Message Format**: All providers use OpenAI-compatible message format internally
4. **Cost Tracking**: Every request calculates cost based on provider-specific pricing tables
5. **Type Safety**: Full type hints and dataclasses for all requests/responses
6. **Lazy Provider Loading**: Providers are instantiated on-demand, not at client initialization
7. **Router Independence**: Router is optional - core functionality works without it

## Project Status

**Current Phase:** Phase 7.4 - Complete ‚úÖ  
**Progress:** Phases 1-6 + Phase 7.1-7.4 Complete  
**Latest Updates:** Phase 7.4 complete - Enhanced Caching UI operational (Feb 3, 2026)

### Completed Phases
- ‚úÖ Phase 1: Core Implementation (100%)
  - BaseProvider abstract class
  - OpenAI provider with cost tracking
  - Unified LLMClient
  - Custom exception hierarchy
  - 32 unit tests passing
- ‚úÖ Phase 2: Provider Expansion (100%)
  - Anthropic provider with Messages API
  - OpenAICompatibleProvider base class
  - Google, DeepSeek, Groq, Grok, Ollama, OpenRouter providers
  - 77 total tests passing
  - All 8 providers operational
- ‚úÖ Phase 3: Advanced Features (100%)
  - Enhanced streaming support
  - Cost tracking module with history
  - Retry logic with exponential backoff
  - Caching and logging decorators
  - Budget management system
- ‚úÖ Phase 3.5: Web GUI (100%)
  - FastAPI REST API with endpoints
  - WebSocket streaming support
  - Interactive frontend interface
  - API documentation and tests
- ‚úÖ Phase 4: Router and Optimization (100%)
  - Router with intelligent model selection
  - Complexity analysis algorithm
  - Cost/quality/latency/hybrid strategies
  - 33 router unit tests passing
- ‚úÖ Phase 5: CLI Interface (100%)
  - Typer CLI framework with 5 commands
  - Rich formatting (tables, colors, progress)
  - Environment variable support
  - Interactive mode with conversation history
  - Router integration
  - Streaming without flicker
  - CLI usage documentation (445 lines)
- ‚úÖ Phase 6: Production Readiness (100%)
  - Complete API documentation
  - 6 example applications
  - Performance optimization
  - Prompt caching system
  - PyPI package preparation
- ‚úÖ Phase 7.1: Large File Handling - Token Estimation & Chunking (100%)
  - Token counting utility with tiktoken (186 lines)
  - File type analyzer with warnings (192 lines)
  - Smart chunking at natural boundaries (158 lines)
  - Progressive summarization (179 lines)
  - CLI integration (--chunked, --chunk-size flags)
  - 19 unit tests passing (16 passing, 3 skipped)
- ‚úÖ Phase 7.2: Intelligent Extraction (100%)
  - CSV schema extractor (197 lines, 26-99% reduction)
  - JSON schema extractor (219 lines, 78-95% reduction)
  - Log error extractor (267 lines, 90% reduction)
  - Code structure extractor (327 lines, 33-80% reduction)
  - `analyze` CLI command
  - pandas dependency
  - 35 unit tests passing (100%)
- ‚úÖ Phase 7.3: Model Auto-Selection (100%)
  - ModelSelector class for file-based selection (324 lines)
  - Router.route_for_extraction() method with quality prioritization
  - --auto-select flag in chat command
  - Auto-selection in analyze command (provider/model flags)
  - ExtractionMode enum (schema/errors/structure/summary)
  - 32 unit tests passing (100%)
  - CSV ‚Üí Claude Sonnet, JSON ‚Üí Claude Sonnet, Logs ‚Üí DeepSeek Reasoner, Code ‚Üí DeepSeek
- ‚úÖ Phase 7.4: Enhanced Caching UI (100%)
  - Enhanced ResponseCache with hit/miss tracking and cost analytics
  - cache-stats command with --detailed flag for entry inspection
  - cache-clear command with confirmation prompt
  - Visual hit rate indicators (üéØ ‚â•75%, ‚ö†Ô∏è ‚â•50%, üìâ <50%)
  - Cost savings analysis showing total saved and average per hit
  - Top 10 cache entries table when --detailed flag used
  - 11 unit tests passing (100%)
- ‚úÖ Interactive Mode Enhancements (100%)
  - Intelligent file extraction integrated into /file and /attach commands
  - Automatic schema extraction for large files (>500KB) with user prompt
  - /save command to export assistant responses with metadata
  - Smart default filenames with timestamps (response_provider_model_timestamp.md)
  - Full metadata in saved files (provider, model, tokens, cost, timestamp)

### Current Focus (Week 7+: Feb 3+)
**Phase 7.5: RAG/Vector DB Integration**
- üìù Vector database integration
- üìù Embedding generation
- üìù Semantic search

**Future Phases:**
- üìù Phase 7.5: RAG/Vector DB Integration
- üìù Phase 8: Production Deployment

### Implementation Phases
1. **Week 1 (Phase 1):** ‚úÖ Core Implementation - BaseProvider, OpenAI, unified client
2. **Week 2 (Phase 2):** ‚úÖ Provider Expansion - All 8 providers operational
3. **Week 3 (Phase 3):** ‚úÖ Advanced Features - Streaming, cost tracking, retry logic
4. **Week 4 (Phase 3.5):** ‚úÖ Web GUI - FastAPI REST API, WebSocket streaming, frontend interface
5. **Week 5 (Phase 4):** ‚úÖ Router and Optimization - Intelligent model selection
6. **Week 6 (Phase 5):** ‚úÖ CLI Interface - Rich/Typer terminal interface (COMPLETE)
7. **Week 7 (Phase 6):** üìù Production Readiness - Documentation, examples, PyPI package

### Next Steps (Immediate - Phase 7.5)
- üìù Vector database integration
- üìù Embedding generation
- üìù Semantic search

### Future Work
- üìù Phase 7.5: RAG/Vector DB Integration
- üìù Phase 8: Production Deployment

## Documentation

### Core Documentation
- **README.md** - Project overview, setup instructions, and usage examples
- **docs/project-status.md** - Detailed 5-week timeline with phase breakdowns (25 working days)
- **docs/stratumai-technical-approach.md** - Comprehensive technical design (1,232 lines)
- **WARP.md** - This file (development environment guidance for Warp AI)

### Key Documentation Sections
- **Technical Approach**: Complete architecture, component design, provider implementations
- **Usage Examples**: Basic usage, streaming, cost tracking, retry with fallbacks
- **Implementation Roadmap**: 5 phases with detailed task breakdowns
- **Testing Strategy**: Unit tests, integration tests, mocking strategies

## Troubleshooting

### Common Issues

**Virtual Environment Not Found:**
```bash
# Recreate if .venv is missing
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

**Dependency Issues:**
```bash
# Update pip
pip install --upgrade pip

# Reinstall dependencies
pip install -r requirements.txt --force-reinstall
```

## Development Best Practices

### Code Style
- Follow PEP 8 for Python code
- Use type hints where appropriate
- Write docstrings for functions and classes
- Keep functions focused and single-purpose

### Git Practices
- Never commit `.env` files or credentials
- Use `.gitignore` for environment files
- Write descriptive commit messages
- Include co-author line: `Co-Authored-By: Warp <agent@warp.dev>`

## Git Commit Convention

Use conventional commit format: `type(scope): brief description`

### Commit Types
- **feat**: New feature or functionality
- **fix**: Bug fix
- **docs**: Documentation changes
- **refactor**: Code refactoring without functionality change
- **test**: Adding or updating tests
- **chore**: Maintenance tasks (dependencies, config, infrastructure)
- **perf**: Performance improvements
- **style**: Code style/formatting changes

### Project Scopes
- **core**: Core functionality
- **api**: API endpoints
- **ui**: User interface
- **data**: Data processing
- **docs**: Documentation
- **tests**: Testing
- **config**: Configuration

### Guidelines
- Keep first line under 72 characters
- Use imperative mood ("add" not "added")
- Always include: `Co-Authored-By: Warp <agent@warp.dev>`
- Scope is optional but recommended
- Reference issues when applicable: `fix(api): resolve connection issue (#123)`

## Technical Constraints

### Must Maintain
- Python 3.10+ compatibility
- Type hints on all functions and methods
- Consistent BaseProvider interface across all providers
- Cost tracking accuracy to $0.0001
- Response time < 2 seconds (p95)
- Test coverage > 80%

### Security Requirements
- Never commit secrets or credentials
- Use environment variables for API keys (OPENAI_API_KEY, ANTHROPIC_API_KEY, etc.)
- Validate all inputs to prevent injection attacks
- Sanitize error messages to avoid leaking API keys
- Use secure vaults for production API key management
- Implement rate limiting and budget enforcement

### Performance Targets
- Response time < 2 seconds (p95) for non-streaming requests
- Cold start < 1 second for provider initialization
- Memory usage < 100MB for client instance
- Cache hit rate > 30% with caching decorator enabled
- Cost reduction > 40% with cost-optimized routing

### Code Quality Standards
- Black formatting compliance (line length 88)
- Ruff linting compliance (all rules enabled)
- Mypy type checking passes with strict mode
- Docstrings on all public classes and methods (Google style)
- Unit test coverage > 80%
- Integration test coverage for all providers
