{
  "version": "1.1.0",
  "updated": "2026-02-11T14:51:00Z",
  "providers": {
    "anthropic": {
      "claude-sonnet-4-20250514": {
        "display_name": "Claude Sonnet 4",
        "description": "Latest flagship model",
        "category": "Claude 4 (Latest)",
        "context": 200000,
        "cost_input": 3.0,
        "cost_output": 15.0,
        "cost_cache_write": 3.75,
        "cost_cache_read": 0.30,
        "supports_vision": true,
        "supports_tools": true,
        "supports_caching": true
      },
      "claude-3-7-sonnet-20250219": {
        "display_name": "Claude 3.7 Sonnet",
        "description": "Advanced reasoning",
        "category": "Claude 3.7",
        "context": 200000,
        "cost_input": 3.0,
        "cost_output": 15.0,
        "cost_cache_write": 3.75,
        "cost_cache_read": 0.30,
        "supports_vision": true,
        "supports_tools": true,
        "supports_caching": true
      },
      "claude-3-5-sonnet-20241022": {
        "display_name": "Claude 3.5 Sonnet",
        "description": "Proven stable, vision/tools",
        "category": "Claude 3.5 (Stable)",
        "context": 200000,
        "cost_input": 3.0,
        "cost_output": 15.0,
        "cost_cache_write": 3.75,
        "cost_cache_read": 0.30,
        "supports_vision": true,
        "supports_tools": true,
        "supports_caching": true
      },
      "claude-3-5-haiku-20241022": {
        "display_name": "Claude 3.5 Haiku",
        "description": "Fast & affordable",
        "category": "Claude 3.5 (Stable)",
        "context": 200000,
        "cost_input": 1.0,
        "cost_output": 5.0,
        "cost_cache_write": 1.25,
        "cost_cache_read": 0.10,
        "supports_vision": true,
        "supports_tools": true,
        "supports_caching": true
      },
      "claude-3-haiku-20240307": {
        "display_name": "Claude 3 Haiku",
        "description": "BEST VALUE - cheapest option",
        "category": "Claude 3",
        "context": 200000,
        "cost_input": 0.25,
        "cost_output": 1.25,
        "supports_vision": true,
        "supports_tools": true,
        "supports_caching": false
      }
    },
    "openai": {
      "gpt-4o": {
        "display_name": "GPT-4o",
        "description": "Best quality, vision/tools support",
        "category": "Current Models",
        "context": 128000,
        "cost_input": 2.5,
        "cost_output": 10.0,
        "cost_cache_write": 1.25,
        "cost_cache_read": 1.25,
        "supports_vision": true,
        "supports_tools": true,
        "supports_caching": true
      },
      "gpt-4o-mini": {
        "display_name": "GPT-4o Mini",
        "description": "BEST VALUE - fast & affordable",
        "category": "Current Models",
        "context": 128000,
        "cost_input": 0.15,
        "cost_output": 0.60,
        "cost_cache_write": 0.075,
        "cost_cache_read": 0.075,
        "supports_vision": true,
        "supports_tools": true,
        "supports_caching": true
      },
      "gpt-4-turbo": {
        "display_name": "GPT-4 Turbo",
        "description": "Legacy flagship, tools support",
        "category": "Legacy Models",
        "context": 128000,
        "cost_input": 10.0,
        "cost_output": 30.0,
        "supports_vision": false,
        "supports_tools": true
      },
      "gpt-4": {
        "display_name": "GPT-4",
        "description": "Original GPT-4",
        "category": "Legacy Models",
        "context": 8192,
        "cost_input": 30.0,
        "cost_output": 60.0,
        "supports_vision": false,
        "supports_tools": true
      },
      "gpt-3.5-turbo": {
        "display_name": "GPT-3.5 Turbo",
        "description": "Fast, affordable",
        "category": "Legacy Models",
        "context": 16385,
        "cost_input": 0.50,
        "cost_output": 1.50,
        "supports_vision": false,
        "supports_tools": true
      },
      "gpt-5": {
        "display_name": "GPT-5",
        "description": "Next-gen flagship (placeholder)",
        "category": "Future Models",
        "context": 128000,
        "cost_input": 10.0,
        "cost_output": 30.0,
        "cost_cache_write": 12.5,
        "cost_cache_read": 1.0,
        "supports_vision": true,
        "supports_tools": true,
        "supports_caching": true,
        "fixed_temperature": 1.0
      },
      "gpt-5-mini": {
        "display_name": "GPT-5 Mini",
        "description": "Compact next-gen (placeholder)",
        "category": "Future Models",
        "context": 128000,
        "cost_input": 2.0,
        "cost_output": 6.0,
        "cost_cache_write": 2.5,
        "cost_cache_read": 0.2,
        "supports_vision": true,
        "supports_tools": true,
        "supports_caching": true
      },
      "gpt-5-nano": {
        "display_name": "GPT-5 Nano",
        "description": "Ultra-compact (placeholder)",
        "category": "Future Models",
        "context": 128000,
        "cost_input": 1.0,
        "cost_output": 3.0,
        "supports_vision": false,
        "supports_tools": true
      },
      "gpt-4.1": {
        "display_name": "GPT-4.1",
        "description": "Enhanced GPT-4",
        "category": "Current Models",
        "context": 128000,
        "cost_input": 2.5,
        "cost_output": 10.0,
        "cost_cache_write": 3.125,
        "cost_cache_read": 0.25,
        "supports_vision": true,
        "supports_tools": true,
        "supports_caching": true
      },
      "gpt-4.1-mini": {
        "display_name": "GPT-4.1 Mini",
        "description": "Compact GPT-4.1",
        "category": "Current Models",
        "context": 128000,
        "cost_input": 0.15,
        "cost_output": 0.60,
        "cost_cache_write": 0.1875,
        "cost_cache_read": 0.015,
        "supports_vision": true,
        "supports_tools": true,
        "supports_caching": true
      },
      "o1": {
        "display_name": "o1",
        "description": "Premium reasoning model",
        "category": "Reasoning Models",
        "context": 200000,
        "cost_input": 15.0,
        "cost_output": 60.0,
        "supports_vision": false,
        "supports_tools": false,
        "reasoning_model": true,
        "fixed_temperature": 1.0
      },
      "o1-mini": {
        "display_name": "o1-mini",
        "description": "Compact reasoning model",
        "category": "Reasoning Models",
        "context": 128000,
        "cost_input": 3.0,
        "cost_output": 12.0,
        "supports_vision": false,
        "supports_tools": false,
        "reasoning_model": true,
        "fixed_temperature": 1.0
      },
      "o3-mini": {
        "display_name": "o3-mini",
        "description": "Cost-effective reasoning",
        "category": "Reasoning Models",
        "context": 200000,
        "cost_input": 1.1,
        "cost_output": 4.4,
        "supports_vision": false,
        "supports_tools": false,
        "reasoning_model": true,
        "fixed_temperature": 1.0
      },
      "o1-preview": {
        "display_name": "o1 Preview",
        "description": "Reasoning preview",
        "category": "Reasoning Models",
        "context": 128000,
        "cost_input": 15.0,
        "cost_output": 60.0,
        "supports_vision": false,
        "supports_tools": false,
        "reasoning_model": true,
        "fixed_temperature": 1.0
      },
      "o1-2024-12-17": {
        "display_name": "o1 (Dec 2024)",
        "description": "Dated o1 release",
        "category": "Reasoning Models",
        "context": 200000,
        "cost_input": 15.0,
        "cost_output": 60.0,
        "supports_vision": false,
        "supports_tools": false,
        "reasoning_model": true,
        "fixed_temperature": 1.0
      },
      "o1-mini-2024-09-12": {
        "display_name": "o1-mini (Sep 2024)",
        "description": "Dated o1-mini release",
        "category": "Reasoning Models",
        "context": 128000,
        "cost_input": 3.0,
        "cost_output": 12.0,
        "supports_vision": false,
        "supports_tools": false,
        "reasoning_model": true,
        "fixed_temperature": 1.0
      }
    },
    "google": {
      "gemini-2.5-pro": {
        "display_name": "Gemini 2.5 Pro",
        "description": "Best quality, 1M context",
        "category": "Gemini 2.5",
        "context": 1000000,
        "cost_input": 1.25,
        "cost_output": 5.0,
        "cost_cache_write": 1.5625,
        "cost_cache_read": 0.125,
        "supports_vision": true,
        "supports_tools": true,
        "supports_caching": true
      },
      "gemini-2.5-flash": {
        "display_name": "Gemini 2.5 Flash",
        "description": "BEST VALUE - fast & cheap",
        "category": "Gemini 2.5",
        "context": 1000000,
        "cost_input": 0.075,
        "cost_output": 0.30,
        "cost_cache_write": 0.09375,
        "cost_cache_read": 0.0075,
        "supports_vision": true,
        "supports_tools": true,
        "supports_caching": true
      },
      "gemini-2.5-flash-lite": {
        "display_name": "Gemini 2.5 Flash Lite",
        "description": "FREE tier option",
        "category": "Gemini 2.5",
        "context": 1000000,
        "cost_input": 0.0,
        "cost_output": 0.0,
        "supports_vision": false,
        "supports_tools": false,
        "free": true
      }
    },
    "deepseek": {
      "deepseek-chat": {
        "display_name": "DeepSeek Chat",
        "description": "General purpose, tools support",
        "category": "DeepSeek",
        "context": 64000,
        "cost_input": 0.14,
        "cost_output": 0.28,
        "supports_vision": false,
        "supports_tools": true
      },
      "deepseek-reasoner": {
        "display_name": "DeepSeek Reasoner",
        "description": "Reasoning model (R1)",
        "category": "DeepSeek",
        "context": 64000,
        "cost_input": 0.55,
        "cost_output": 2.19,
        "supports_vision": false,
        "supports_tools": false,
        "reasoning_model": true,
        "fixed_temperature": 1.0
      }
    },
    "groq": {
      "llama-3.3-70b-versatile": {
        "display_name": "Llama 3.3 70B",
        "description": "Best quality open model",
        "category": "Llama Models",
        "context": 128000,
        "cost_input": 0.59,
        "cost_output": 0.79,
        "supports_vision": false,
        "supports_tools": true
      },
      "llama-3.3-70b-specdec": {
        "display_name": "Llama 3.3 70B SpecDec",
        "description": "Speculative decoding",
        "category": "Llama Models",
        "context": 128000,
        "cost_input": 0.59,
        "cost_output": 0.79,
        "supports_vision": false,
        "supports_tools": true
      },
      "llama-3.1-70b-versatile": {
        "display_name": "Llama 3.1 70B",
        "description": "Legacy stable model",
        "category": "Llama Models",
        "context": 128000,
        "cost_input": 0.59,
        "cost_output": 0.79,
        "supports_vision": false,
        "supports_tools": true
      },
      "llama-3.1-8b-instant": {
        "display_name": "Llama 3.1 8B",
        "description": "FASTEST - ultra low latency",
        "category": "Llama Models",
        "context": 128000,
        "cost_input": 0.05,
        "cost_output": 0.08,
        "supports_vision": false,
        "supports_tools": true
      },
      "llama-3-groq-70b-tool-use": {
        "display_name": "Llama 3 Groq 70B Tool",
        "description": "Optimized for tool use",
        "category": "Tool Use Models",
        "context": 8192,
        "cost_input": 0.89,
        "cost_output": 0.89,
        "supports_vision": false,
        "supports_tools": true
      },
      "llama-3-groq-8b-tool-use": {
        "display_name": "Llama 3 Groq 8B Tool",
        "description": "Fast tool use",
        "category": "Tool Use Models",
        "context": 8192,
        "cost_input": 0.19,
        "cost_output": 0.19,
        "supports_vision": false,
        "supports_tools": true
      },
      "openai/gpt-oss-120b": {
        "display_name": "GPT-OSS 120B",
        "description": "OpenAI open-weight reasoning",
        "category": "Reasoning Models",
        "context": 128000,
        "cost_input": 0.59,
        "cost_output": 0.79,
        "supports_vision": false,
        "supports_tools": true,
        "reasoning_model": true
      },
      "openai/gpt-oss-20b": {
        "display_name": "GPT-OSS 20B",
        "description": "Compact open-weight reasoning",
        "category": "Reasoning Models",
        "context": 128000,
        "cost_input": 0.05,
        "cost_output": 0.08,
        "supports_vision": false,
        "supports_tools": true,
        "reasoning_model": true
      },
      "groq/compound": {
        "display_name": "Compound AI",
        "description": "Multi-model system",
        "category": "Groq Native",
        "context": 128000,
        "cost_input": 0.59,
        "cost_output": 0.79,
        "supports_vision": false,
        "supports_tools": true
      }
    },
    "grok": {
      "grok-4-1-fast-reasoning": {
        "display_name": "Grok 4.1 Fast (Reasoning)",
        "description": "BEST VALUE - 2M context, agentic tools",
        "category": "Grok 4.1 Fast (Latest)",
        "context": 2000000,
        "cost_input": 0.20,
        "cost_output": 0.50,
        "supports_vision": true,
        "supports_tools": true,
        "reasoning_model": true
      },
      "grok-4-1-fast-non-reasoning": {
        "display_name": "Grok 4.1 Fast (Non-Reasoning)",
        "description": "FASTEST - instant responses, 2M context",
        "category": "Grok 4.1 Fast (Latest)",
        "context": 2000000,
        "cost_input": 0.20,
        "cost_output": 0.50,
        "supports_vision": true,
        "supports_tools": true
      },
      "grok-4-fast-reasoning": {
        "display_name": "Grok 4 Fast (Reasoning)",
        "description": "High performance reasoning",
        "category": "Grok 4",
        "context": 2000000,
        "cost_input": 0.50,
        "cost_output": 1.50,
        "supports_vision": true,
        "supports_tools": true,
        "reasoning_model": true
      },
      "grok-4-fast-non-reasoning": {
        "display_name": "Grok 4 Fast (Non-Reasoning)",
        "description": "High performance standard",
        "category": "Grok 4",
        "context": 2000000,
        "cost_input": 0.50,
        "cost_output": 1.50,
        "supports_vision": true,
        "supports_tools": true
      },
      "grok-4": {
        "display_name": "Grok 4",
        "description": "Flagship reasoning model",
        "category": "Grok 4 (Premium)",
        "context": 128000,
        "cost_input": 5.0,
        "cost_output": 15.0,
        "supports_vision": true,
        "supports_tools": true,
        "reasoning_model": true,
        "fixed_temperature": 1.0
      },
      "grok-code-fast-1": {
        "display_name": "Grok Code Fast",
        "description": "FREE - specialized for coding",
        "category": "Grok Specialized",
        "context": 256000,
        "cost_input": 0.0,
        "cost_output": 0.0,
        "supports_vision": false,
        "supports_tools": true,
        "reasoning_model": true,
        "free": true
      },
      "grok-3": {
        "display_name": "Grok 3",
        "description": "Stable production model",
        "category": "Grok 3",
        "context": 128000,
        "cost_input": 2.0,
        "cost_output": 10.0,
        "supports_vision": true,
        "supports_tools": true
      },
      "grok-3-fast": {
        "display_name": "Grok 3 Fast",
        "description": "Faster Grok 3 variant",
        "category": "Grok 3",
        "context": 128000,
        "cost_input": 1.0,
        "cost_output": 5.0,
        "supports_vision": true,
        "supports_tools": true
      },
      "grok-3-mini": {
        "display_name": "Grok 3 Mini",
        "description": "Configurable reasoning effort",
        "category": "Grok 3",
        "context": 128000,
        "cost_input": 0.40,
        "cost_output": 1.60,
        "supports_vision": false,
        "supports_tools": true,
        "reasoning_model": true
      },
      "grok-3-mini-fast": {
        "display_name": "Grok 3 Mini Fast",
        "description": "Fast compact reasoning",
        "category": "Grok 3",
        "context": 128000,
        "cost_input": 0.20,
        "cost_output": 0.80,
        "supports_vision": false,
        "supports_tools": true,
        "reasoning_model": true
      },
      "grok-2-1212": {
        "display_name": "Grok 2",
        "description": "Legacy stable model",
        "category": "Grok 2 (Legacy)",
        "context": 131072,
        "cost_input": 2.0,
        "cost_output": 10.0,
        "supports_vision": false,
        "supports_tools": true
      },
      "grok-2-vision": {
        "display_name": "Grok 2 Vision",
        "description": "Legacy vision model",
        "category": "Grok 2 (Legacy)",
        "context": 131072,
        "cost_input": 2.0,
        "cost_output": 10.0,
        "supports_vision": true,
        "supports_tools": true
      },
      "grok-beta": {
        "display_name": "Grok Beta",
        "description": "Original beta model",
        "category": "Grok 2 (Legacy)",
        "context": 131072,
        "cost_input": 5.0,
        "cost_output": 15.0,
        "supports_vision": false,
        "supports_tools": true
      }
    },
    "openrouter": {
      "anthropic/claude-opus-4-5": {
        "display_name": "Claude Opus 4.5",
        "description": "Premium quality, 1M context",
        "category": "1M Context Models",
        "context": 1000000,
        "cost_input": 5.0,
        "cost_output": 25.0,
        "supports_vision": true,
        "supports_tools": true,
        "supports_caching": true
      },
      "anthropic/claude-sonnet-4-5": {
        "display_name": "Claude Sonnet 4.5",
        "description": "Best Anthropic model",
        "category": "Premium Models",
        "context": 200000,
        "cost_input": 3.0,
        "cost_output": 15.0,
        "supports_vision": true,
        "supports_tools": true,
        "supports_caching": true
      },
      "anthropic/claude-haiku-4-5": {
        "display_name": "Claude Haiku 4.5",
        "description": "Fast Anthropic model",
        "category": "Premium Models",
        "context": 200000,
        "cost_input": 0.80,
        "cost_output": 4.0,
        "supports_vision": true,
        "supports_tools": true,
        "supports_caching": true
      },
      "anthropic/claude-3-7-sonnet": {
        "display_name": "Claude 3.7 Sonnet",
        "description": "Advanced reasoning",
        "category": "Premium Models",
        "context": 200000,
        "cost_input": 3.0,
        "cost_output": 15.0,
        "supports_vision": true,
        "supports_tools": true,
        "supports_caching": true
      },
      "anthropic/claude-3-5-sonnet": {
        "display_name": "Claude 3.5 Sonnet",
        "description": "Stable production model",
        "category": "Premium Models",
        "context": 200000,
        "cost_input": 3.0,
        "cost_output": 15.0,
        "supports_vision": true,
        "supports_tools": true
      },
      "openai/gpt-5.2": {
        "display_name": "GPT-5.2",
        "description": "Next-gen OpenAI",
        "category": "Premium Models",
        "context": 400000,
        "cost_input": 10.0,
        "cost_output": 30.0,
        "supports_vision": true,
        "supports_tools": true,
        "supports_caching": true
      },
      "openai/gpt-5.1": {
        "display_name": "GPT-5.1",
        "description": "Advanced OpenAI",
        "category": "Premium Models",
        "context": 200000,
        "cost_input": 10.0,
        "cost_output": 30.0,
        "supports_vision": true,
        "supports_tools": true
      },
      "openai/gpt-4o": {
        "display_name": "GPT-4o",
        "description": "Best OpenAI model",
        "category": "Premium Models",
        "context": 128000,
        "cost_input": 2.5,
        "cost_output": 10.0,
        "supports_vision": true,
        "supports_tools": true,
        "supports_caching": true
      },
      "openai/gpt-4o-mini": {
        "display_name": "GPT-4o Mini",
        "description": "Fast & affordable",
        "category": "Premium Models",
        "context": 128000,
        "cost_input": 0.15,
        "cost_output": 0.60,
        "supports_vision": true,
        "supports_tools": true,
        "supports_caching": true
      },
      "openai/gpt-4-turbo": {
        "display_name": "GPT-4 Turbo",
        "description": "Legacy flagship",
        "category": "Premium Models",
        "context": 128000,
        "cost_input": 10.0,
        "cost_output": 30.0,
        "supports_vision": true,
        "supports_tools": true
      },
      "openai/gpt-4": {
        "display_name": "GPT-4",
        "description": "Original GPT-4",
        "category": "Legacy Models",
        "context": 8192,
        "cost_input": 30.0,
        "cost_output": 60.0,
        "supports_vision": false,
        "supports_tools": true
      },
      "openai/gpt-3.5-turbo": {
        "display_name": "GPT-3.5 Turbo",
        "description": "Fast, affordable",
        "category": "Legacy Models",
        "context": 16385,
        "cost_input": 0.50,
        "cost_output": 1.50,
        "supports_vision": false,
        "supports_tools": true
      },
      "openai/o1": {
        "display_name": "o1",
        "description": "Premium reasoning",
        "category": "Reasoning Models",
        "context": 200000,
        "cost_input": 15.0,
        "cost_output": 60.0,
        "supports_vision": false,
        "supports_tools": false,
        "reasoning_model": true,
        "fixed_temperature": 1.0
      },
      "openai/o1-mini": {
        "display_name": "o1-mini",
        "description": "Compact reasoning",
        "category": "Reasoning Models",
        "context": 128000,
        "cost_input": 3.0,
        "cost_output": 12.0,
        "supports_vision": false,
        "supports_tools": false,
        "reasoning_model": true,
        "fixed_temperature": 1.0
      },
      "openai/o3-mini": {
        "display_name": "o3-mini",
        "description": "Cost-effective reasoning",
        "category": "Reasoning Models",
        "context": 200000,
        "cost_input": 1.1,
        "cost_output": 4.4,
        "supports_vision": false,
        "supports_tools": false,
        "reasoning_model": true,
        "fixed_temperature": 1.0
      },
      "google/gemini-3": {
        "display_name": "Gemini 3",
        "description": "Latest Google, 1M context",
        "category": "1M Context Models",
        "context": 1000000,
        "cost_input": 2.5,
        "cost_output": 10.0,
        "supports_vision": true,
        "supports_tools": true,
        "supports_caching": true
      },
      "google/gemini-2.5-pro": {
        "display_name": "Gemini 2.5 Pro",
        "description": "Best quality, 1M context",
        "category": "1M Context Models",
        "context": 1000000,
        "cost_input": 1.25,
        "cost_output": 5.0,
        "supports_vision": true,
        "supports_tools": true,
        "supports_caching": true
      },
      "google/gemini-2.5-flash": {
        "display_name": "Gemini 2.5 Flash",
        "description": "BEST VALUE - 1M context, fast/cheap",
        "category": "Premium Models",
        "context": 1000000,
        "cost_input": 0.075,
        "cost_output": 0.30,
        "supports_vision": true,
        "supports_tools": true,
        "supports_caching": true
      },
      "google/gemini-2.5-flash-lite": {
        "display_name": "Gemini 2.5 Flash Lite",
        "description": "FREE tier option",
        "category": "Free Models",
        "context": 1000000,
        "cost_input": 0.0,
        "cost_output": 0.0,
        "supports_vision": false,
        "supports_tools": false,
        "free": true
      },
      "google/gemini-2.0-flash-exp:free": {
        "display_name": "Gemini 2.0 Flash Exp",
        "description": "FREE - 1M context, vision/tools",
        "category": "Free Models (1M Context)",
        "context": 1000000,
        "cost_input": 0.0,
        "cost_output": 0.0,
        "supports_vision": true,
        "supports_tools": true,
        "free": true
      },
      "meta-llama/llama-4-maverick:free": {
        "display_name": "Llama 4 Maverick",
        "description": "FREE - 512K context",
        "category": "Free Models",
        "context": 512000,
        "cost_input": 0.0,
        "cost_output": 0.0,
        "supports_vision": true,
        "supports_tools": true,
        "free": true
      },
      "meta-llama/llama-4-scout:free": {
        "display_name": "Llama 4 Scout",
        "description": "FREE - 512K context",
        "category": "Free Models",
        "context": 512000,
        "cost_input": 0.0,
        "cost_output": 0.0,
        "supports_vision": true,
        "supports_tools": true,
        "free": true
      },
      "meta-llama/llama-3.3-70b-instruct": {
        "display_name": "Llama 3.3 70B",
        "description": "Best open model",
        "category": "Llama Models",
        "context": 128000,
        "cost_input": 0.35,
        "cost_output": 0.40,
        "supports_vision": false,
        "supports_tools": true
      },
      "meta-llama/llama-3.3-70b-instruct:free": {
        "display_name": "Llama 3.3 70B Free",
        "description": "FREE - best open model",
        "category": "Free Models",
        "context": 128000,
        "cost_input": 0.0,
        "cost_output": 0.0,
        "supports_vision": false,
        "supports_tools": true,
        "free": true
      },
      "meta-llama/llama-3.1-70b-versatile": {
        "display_name": "Llama 3.1 70B",
        "description": "Versatile open model",
        "category": "Llama Models",
        "context": 131072,
        "cost_input": 0.59,
        "cost_output": 0.79,
        "supports_vision": false,
        "supports_tools": true
      },
      "meta-llama/llama-3.1-8b-instant": {
        "display_name": "Llama 3.1 8B",
        "description": "Fast small model",
        "category": "Llama Models",
        "context": 131072,
        "cost_input": 0.05,
        "cost_output": 0.08,
        "supports_vision": false,
        "supports_tools": true
      },
      "deepseek/deepseek-v3.2": {
        "display_name": "DeepSeek V3.2",
        "description": "Latest DeepSeek",
        "category": "DeepSeek Models",
        "context": 64000,
        "cost_input": 0.14,
        "cost_output": 0.28,
        "supports_vision": false,
        "supports_tools": true
      },
      "deepseek/deepseek-chat": {
        "display_name": "DeepSeek Chat",
        "description": "General purpose",
        "category": "DeepSeek Models",
        "context": 64000,
        "cost_input": 0.14,
        "cost_output": 0.28,
        "supports_vision": false,
        "supports_tools": true
      },
      "deepseek/deepseek-chat-v3-0324:free": {
        "display_name": "DeepSeek V3 Free",
        "description": "FREE - excellent quality",
        "category": "Free Models",
        "context": 64000,
        "cost_input": 0.0,
        "cost_output": 0.0,
        "supports_vision": false,
        "supports_tools": true,
        "free": true
      },
      "deepseek/deepseek-reasoner": {
        "display_name": "DeepSeek Reasoner",
        "description": "Reasoning model",
        "category": "Reasoning Models",
        "context": 64000,
        "cost_input": 0.55,
        "cost_output": 2.19,
        "supports_vision": false,
        "supports_tools": false,
        "reasoning_model": true,
        "fixed_temperature": 1.0
      },
      "deepseek/deepseek-r1": {
        "display_name": "DeepSeek R1",
        "description": "Reasoning model",
        "category": "Reasoning Models",
        "context": 64000,
        "cost_input": 0.55,
        "cost_output": 2.19,
        "supports_vision": false,
        "supports_tools": false,
        "reasoning_model": true,
        "fixed_temperature": 1.0
      },
      "deepseek/deepseek-r1-zero:free": {
        "display_name": "DeepSeek R1 Zero",
        "description": "FREE reasoning model",
        "category": "Free Models",
        "context": 64000,
        "cost_input": 0.0,
        "cost_output": 0.0,
        "supports_vision": false,
        "supports_tools": false,
        "reasoning_model": true,
        "fixed_temperature": 1.0,
        "free": true
      },
      "deepseek/deepseek-v3-base:free": {
        "display_name": "DeepSeek V3 Base",
        "description": "FREE base model",
        "category": "Free Models",
        "context": 64000,
        "cost_input": 0.0,
        "cost_output": 0.0,
        "supports_vision": false,
        "supports_tools": true,
        "free": true
      },
      "mistralai/mistral-large-3": {
        "display_name": "Mistral Large 3",
        "description": "European alternative",
        "category": "Premium Models",
        "context": 128000,
        "cost_input": 2.0,
        "cost_output": 6.0,
        "supports_vision": false,
        "supports_tools": true
      },
      "mistralai/mistral-small-3.1-24b-instruct:free": {
        "display_name": "Mistral Small 3.1",
        "description": "FREE Mistral model",
        "category": "Free Models",
        "context": 128000,
        "cost_input": 0.0,
        "cost_output": 0.0,
        "supports_vision": false,
        "supports_tools": true,
        "free": true
      },
      "mistralai/devstral-2:free": {
        "display_name": "Devstral 2",
        "description": "FREE - 256K coding model",
        "category": "Free Models",
        "context": 256000,
        "cost_input": 0.0,
        "cost_output": 0.0,
        "supports_vision": false,
        "supports_tools": true,
        "free": true
      },
      "mistralai/mixtral-8x7b-32768": {
        "display_name": "Mixtral 8x7B",
        "description": "MoE model",
        "category": "Mistral Models",
        "context": 32768,
        "cost_input": 0.24,
        "cost_output": 0.24,
        "supports_vision": false,
        "supports_tools": true
      },
      "qwen/qwen-3-32b": {
        "display_name": "Qwen 3 32B",
        "description": "Alibaba model",
        "category": "Qwen Models",
        "context": 128000,
        "cost_input": 0.40,
        "cost_output": 0.60,
        "supports_vision": false,
        "supports_tools": true
      },
      "qwen/qwen2.5-vl-3b-instruct:free": {
        "display_name": "Qwen 2.5 VL 3B",
        "description": "FREE vision model",
        "category": "Free Models",
        "context": 32000,
        "cost_input": 0.0,
        "cost_output": 0.0,
        "supports_vision": true,
        "supports_tools": false,
        "free": true
      },
      "x-ai/grok-4.1-fast": {
        "display_name": "Grok 4.1 Fast",
        "description": "1.8M context",
        "category": "Premium Models",
        "context": 1800000,
        "cost_input": 5.0,
        "cost_output": 15.0,
        "supports_vision": true,
        "supports_tools": true
      },
      "x-ai/grok-beta": {
        "display_name": "Grok Beta",
        "description": "Original Grok",
        "category": "Premium Models",
        "context": 131072,
        "cost_input": 5.0,
        "cost_output": 15.0,
        "supports_vision": false,
        "supports_tools": true
      },
      "nvidia/llama-3.1-nemotron-nano-8b-v1:free": {
        "display_name": "Nemotron Nano 8B",
        "description": "FREE NVIDIA model",
        "category": "Free Models",
        "context": 128000,
        "cost_input": 0.0,
        "cost_output": 0.0,
        "supports_vision": false,
        "supports_tools": true,
        "free": true
      },
      "nvidia/nemotron-nano-2-vl:free": {
        "display_name": "Nemotron Nano 2 VL",
        "description": "FREE vision model",
        "category": "Free Models",
        "context": 128000,
        "cost_input": 0.0,
        "cost_output": 0.0,
        "supports_vision": true,
        "supports_tools": false,
        "free": true
      },
      "moonshotai/kimi-vl-a3b-thinking:free": {
        "display_name": "Kimi VL A3B",
        "description": "FREE vision+reasoning",
        "category": "Free Models",
        "context": 128000,
        "cost_input": 0.0,
        "cost_output": 0.0,
        "supports_vision": true,
        "supports_tools": false,
        "reasoning_model": true,
        "free": true
      },
      "zhipuai/glm-4.5-air:free": {
        "display_name": "GLM 4.5 Air",
        "description": "FREE Chinese model",
        "category": "Free Models",
        "context": 128000,
        "cost_input": 0.0,
        "cost_output": 0.0,
        "supports_vision": false,
        "supports_tools": true,
        "free": true
      },
      "zhipuai/glm-4-32b": {
        "display_name": "GLM 4 32B",
        "description": "Chinese model",
        "category": "Zhipu Models",
        "context": 128000,
        "cost_input": 0.50,
        "cost_output": 0.50,
        "supports_vision": false,
        "supports_tools": true
      },
      "nousresearch/deephermes-3-llama-3-8b-preview:free": {
        "display_name": "DeepHermes 3 8B",
        "description": "FREE Nous model",
        "category": "Free Models",
        "context": 8192,
        "cost_input": 0.0,
        "cost_output": 0.0,
        "supports_vision": false,
        "supports_tools": false,
        "free": true
      },
      "arcee/trinity-large-preview:free": {
        "display_name": "Trinity Large",
        "description": "FREE Arcee model",
        "category": "Free Models",
        "context": 128000,
        "cost_input": 0.0,
        "cost_output": 0.0,
        "supports_vision": false,
        "supports_tools": true,
        "free": true
      },
      "openrouter/optimus-alpha": {
        "display_name": "Optimus Alpha",
        "description": "FREE OpenRouter native",
        "category": "Free Models",
        "context": 128000,
        "cost_input": 0.0,
        "cost_output": 0.0,
        "supports_vision": false,
        "supports_tools": true,
        "free": true
      },
      "openrouter/quasar-alpha": {
        "display_name": "Quasar Alpha",
        "description": "FREE OpenRouter native",
        "category": "Free Models",
        "context": 128000,
        "cost_input": 0.0,
        "cost_output": 0.0,
        "supports_vision": false,
        "supports_tools": true,
        "free": true
      }
    },
    "ollama": {
      "llama3.2": {
        "display_name": "Llama 3.2",
        "description": "Best local model",
        "category": "Local Models",
        "context": 128000,
        "cost_input": 0.0,
        "cost_output": 0.0,
        "supports_vision": false,
        "supports_tools": false,
        "free": true
      },
      "mistral": {
        "display_name": "Mistral",
        "description": "Fast & efficient",
        "category": "Local Models",
        "context": 32768,
        "cost_input": 0.0,
        "cost_output": 0.0,
        "supports_vision": false,
        "supports_tools": false,
        "free": true
      },
      "codellama": {
        "display_name": "Code Llama",
        "description": "Code specialist",
        "category": "Local Models",
        "context": 16384,
        "cost_input": 0.0,
        "cost_output": 0.0,
        "supports_vision": false,
        "supports_tools": false,
        "free": true
      }
    },
    "bedrock": {
      "anthropic.claude-3-5-sonnet-20241022-v2:0": {
        "display_name": "Claude 3.5 Sonnet v2",
        "description": "High quality, vision/tools",
        "category": "Anthropic Claude 3.5",
        "context": 200000,
        "cost_input": 3.0,
        "cost_output": 15.0,
        "supports_vision": true,
        "supports_tools": true,
        "supports_caching": false
      },
      "anthropic.claude-3-5-haiku-20241022-v1:0": {
        "display_name": "Claude 3.5 Haiku",
        "description": "Fast & cheap Claude",
        "category": "Anthropic Claude 3.5",
        "context": 200000,
        "cost_input": 1.0,
        "cost_output": 5.0,
        "supports_vision": true,
        "supports_tools": true,
        "supports_caching": false
      },
      "anthropic.claude-3-opus-20240229-v1:0": {
        "display_name": "Claude 3 Opus",
        "description": "Premium Claude 3",
        "category": "Anthropic Claude 3",
        "context": 200000,
        "cost_input": 15.0,
        "cost_output": 75.0,
        "supports_vision": true,
        "supports_tools": true,
        "supports_caching": false
      },
      "anthropic.claude-3-sonnet-20240229-v1:0": {
        "display_name": "Claude 3 Sonnet",
        "description": "High quality, vision/tools",
        "category": "Anthropic Claude 3",
        "context": 200000,
        "cost_input": 3.0,
        "cost_output": 15.0,
        "supports_vision": true,
        "supports_tools": true,
        "supports_caching": false
      },
      "anthropic.claude-3-haiku-20240307-v1:0": {
        "display_name": "Claude 3 Haiku",
        "description": "Fast & cheap Claude",
        "category": "Anthropic Claude 3",
        "context": 200000,
        "cost_input": 0.25,
        "cost_output": 1.25,
        "supports_vision": true,
        "supports_tools": true,
        "supports_caching": false
      },
      "meta.llama3-3-70b-instruct-v1:0": {
        "display_name": "Llama 3.3 70B",
        "description": "Best Meta model",
        "category": "Meta Llama",
        "context": 128000,
        "cost_input": 0.99,
        "cost_output": 0.99,
        "supports_vision": false,
        "supports_tools": false
      },
      "meta.llama3-2-90b-instruct-v1:0": {
        "display_name": "Llama 3.2 90B",
        "description": "Large Meta model",
        "category": "Meta Llama",
        "context": 128000,
        "cost_input": 1.20,
        "cost_output": 1.20,
        "supports_vision": false,
        "supports_tools": false
      },
      "meta.llama3-1-70b-instruct-v1:0": {
        "display_name": "Llama 3.1 70B",
        "description": "Stable Meta model",
        "category": "Meta Llama",
        "context": 128000,
        "cost_input": 0.99,
        "cost_output": 0.99,
        "supports_vision": false,
        "supports_tools": false
      },
      "meta.llama3-1-8b-instruct-v1:0": {
        "display_name": "Llama 3.1 8B",
        "description": "Fast small Meta model",
        "category": "Meta Llama",
        "context": 128000,
        "cost_input": 0.22,
        "cost_output": 0.22,
        "supports_vision": false,
        "supports_tools": false
      },
      "mistral.mistral-large-2402-v1:0": {
        "display_name": "Mistral Large",
        "description": "Large Mistral model",
        "category": "Mistral AI",
        "context": 128000,
        "cost_input": 3.0,
        "cost_output": 9.0,
        "supports_vision": false,
        "supports_tools": true
      },
      "mistral.mistral-small-2402-v1:0": {
        "display_name": "Mistral Small",
        "description": "Fast Mistral model",
        "category": "Mistral AI",
        "context": 32000,
        "cost_input": 1.0,
        "cost_output": 3.0,
        "supports_vision": false,
        "supports_tools": true
      },
      "amazon.nova-pro-v1:0": {
        "display_name": "Nova Pro",
        "description": "Best Nova quality, vision",
        "category": "Amazon Nova",
        "context": 300000,
        "cost_input": 0.80,
        "cost_output": 3.20,
        "supports_vision": true,
        "supports_tools": false
      },
      "amazon.nova-lite-v1:0": {
        "display_name": "Nova Lite",
        "description": "BEST VALUE - 96% cheaper",
        "category": "Amazon Nova",
        "context": 300000,
        "cost_input": 0.06,
        "cost_output": 0.24,
        "supports_vision": true,
        "supports_tools": false
      },
      "amazon.nova-micro-v1:0": {
        "display_name": "Nova Micro",
        "description": "FASTEST/CHEAPEST",
        "category": "Amazon Nova",
        "context": 128000,
        "cost_input": 0.035,
        "cost_output": 0.14,
        "supports_vision": false,
        "supports_tools": false
      },
      "cohere.command-r-plus-v1:0": {
        "display_name": "Command R+",
        "description": "Premium Cohere model",
        "category": "Cohere",
        "context": 128000,
        "cost_input": 3.0,
        "cost_output": 15.0,
        "supports_vision": false,
        "supports_tools": true
      },
      "cohere.command-r-v1:0": {
        "display_name": "Command R",
        "description": "Standard Cohere model",
        "category": "Cohere",
        "context": 128000,
        "cost_input": 0.50,
        "cost_output": 1.50,
        "supports_vision": false,
        "supports_tools": true
      }
    }
  }
}
